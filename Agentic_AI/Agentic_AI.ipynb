{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stardog Knowledge Graph Setup and Configuration\n",
        "1. Configure Stardog connection using environment variables\n",
        "2. Create a StardogClient class for handling database operations\n",
        "3. Implement query, get_schema and update methods for SPARQL operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import stardog\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Stardog configuration\n",
        "STARDOG_ENDPOINT = os.getenv(\"STARDOG_ENDPOINT\")\n",
        "STARDOG_DATABASE = os.getenv(\"STARDOG_DATABASE\")\n",
        "STARDOG_USERNAME = os.getenv(\"STARDOG_USERNAME\")\n",
        "STARDOG_PASSWORD = os.getenv(\"STARDOG_PASSWORD\")\n",
        "\n",
        "print(\"STARDOG_DATABASE: \", STARDOG_DATABASE)\n",
        "\n",
        "# StardogClient class for database connection and queries\n",
        "class StardogClient:\n",
        "    def __init__(self, endpoint, database, username, password):\n",
        "        self.endpoint = endpoint\n",
        "        self.database = database\n",
        "        self.connection_details = {\n",
        "            'endpoint': endpoint,\n",
        "            'username': username,\n",
        "            'password': password\n",
        "        }\n",
        "        self.database = database\n",
        "\n",
        "    def query(self, sparql_query, use_reasoning=True):\n",
        "        \"\"\"Execute a SPARQL query against Stardog\"\"\"\n",
        "        try:\n",
        "            with stardog.Connection(self.database, **self.connection_details) as conn:\n",
        "                # Execute the query with reasoning if enabled\n",
        "                result = conn.select(sparql_query, reasoning=use_reasoning)\n",
        "                return result\n",
        "        except Exception as e:\n",
        "            print(f\"Error executing SPARQL query: {e}\")\n",
        "            return None\n",
        "\n",
        "    def update(self, sparql_update):\n",
        "        \"\"\"Execute a SPARQL UPDATE query\"\"\"\n",
        "        try:\n",
        "            with stardog.Connection(self.database, **self.connection_details) as conn:\n",
        "                conn.begin()\n",
        "                conn.update(sparql_update)\n",
        "                conn.commit()\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error executing SPARQL update: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_schema(self):\n",
        "        \"\"\"Get the ontology schema from the knowledge graph, including classes, properties, and their domains and ranges.\"\"\"\n",
        "        schema_details_query = \"\"\"\n",
        "        SELECT ?s ?p ?o\n",
        "        FROM <https://a.in/sales/ontology>\n",
        "        WHERE {\n",
        "            ?s ?p ?o\n",
        "        }\n",
        "        \"\"\"\n",
        "        schema_result = self.query(schema_details_query, use_reasoning=False)\n",
        "        if schema_result and schema_result.get('results', {}).get('bindings'):\n",
        "            triples = schema_result['results']['bindings']\n",
        "\n",
        "            classes = set()\n",
        "            object_properties = {}\n",
        "            datatype_properties = {}\n",
        "\n",
        "            ontology_base = 'https://a.in/sales/ontology#'\n",
        "            def short_name(uri):\n",
        "                return uri[len(ontology_base):] if uri.startswith(ontology_base) else uri\n",
        "\n",
        "            for triple in triples:\n",
        "                subject = triple['s']['value']\n",
        "                predicate = triple['p']['value']\n",
        "                obj = triple['o']['value']\n",
        "\n",
        "                # Identify classes\n",
        "                if predicate == 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type':\n",
        "                    if obj == 'http://www.w3.org/2002/07/owl#Class':\n",
        "                        cls = short_name(subject)\n",
        "                        if cls != 'https://a.in/sales/ontology':\n",
        "                            classes.add(cls)\n",
        "                    elif obj == 'http://www.w3.org/2002/07/owl#ObjectProperty':\n",
        "                        op = short_name(subject)\n",
        "                        if op not in object_properties:\n",
        "                            object_properties[op] = {'domain': None, 'range': None}\n",
        "                    elif obj == 'http://www.w3.org/2002/07/owl#DatatypeProperty':\n",
        "                        dp = short_name(subject)\n",
        "                        if dp not in datatype_properties:\n",
        "                            datatype_properties[dp] = {'domain': None, 'range': None}\n",
        "\n",
        "                # Identify domain/range\n",
        "                if predicate == 'http://www.w3.org/2000/01/rdf-schema#domain':\n",
        "                    prop = short_name(subject)\n",
        "                    val = short_name(obj)\n",
        "                    if prop in object_properties:\n",
        "                        object_properties[prop]['domain'] = val\n",
        "                    elif prop in datatype_properties:\n",
        "                        datatype_properties[prop]['domain'] = val\n",
        "                if predicate == 'http://www.w3.org/2000/01/rdf-schema#range':\n",
        "                    prop = short_name(subject)\n",
        "                    val = short_name(obj)\n",
        "                    if prop in object_properties:\n",
        "                        object_properties[prop]['range'] = val\n",
        "                    elif prop in datatype_properties:\n",
        "                        datatype_properties[prop]['range'] = val\n",
        "\n",
        "            return {\n",
        "                'classes': sorted(classes),\n",
        "                'object_properties': object_properties,\n",
        "                'datatype_properties': datatype_properties,\n",
        "                'raw_result': schema_result\n",
        "            }\n",
        "        return None\n",
        "\n",
        "# Initialize Stardog client\n",
        "stardog_client = StardogClient(STARDOG_ENDPOINT, STARDOG_DATABASE, STARDOG_USERNAME, STARDOG_PASSWORD)\n",
        "print(\"Stardog KG client initialized successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SPARQL Agent Implementation\n",
        "- Environment setup (OpenAI configuration)\n",
        "- Required imports for the agent\n",
        "- Type definitions and state management\n",
        "- Prefix definitions for the e-commerce ontology"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sparql_agent.py\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langgraph.graph import StateGraph, END\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Open AI configuration\n",
        "load_dotenv()\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "OPENAI_BASE_URL = \"https://api.openai.com/v1\"\n",
        "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")  # Default model\n",
        "\n",
        "# Ontology prefixes for e-commerce domain\n",
        "PREFIXES = \"\"\"\n",
        "PREFIX ex: <https://a.in/sales/ontology#>\n",
        "PREFIX data: <https://a.in/sales/data#>\n",
        "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
        "PREFIX schema: <http://schema.org/>\n",
        "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
        "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
        "\"\"\"\n",
        "\n",
        "# Initialize LLM with OpenAI configuration\n",
        "# Returns a ChatOpenAI instance configured with temperature=1 and model/API settings from environment\n",
        "def llm_from_api():\n",
        "    return ChatOpenAI(\n",
        "        temperature=1,\n",
        "        base_url=OPENAI_BASE_URL,\n",
        "        api_key=OPENAI_API_KEY,\n",
        "        model=OPENAI_MODEL\n",
        "    )\n",
        "\n",
        "# Define the state for the agent\n",
        "class AgentState(TypedDict):\n",
        "    question: str\n",
        "    sparql_query: str\n",
        "    query_result: str\n",
        "    query_results: list\n",
        "    attempts: int\n",
        "    relevance: str\n",
        "    sparql_error: bool\n",
        "\n",
        "# Get the schema from the knowledge graph and format it for the LLM\n",
        "def get_kg_schema():\n",
        "    \"\"\"Get a formatted schema summary with classes and relationships in the requested format.\"\"\"\n",
        "    schema = stardog_client.get_schema()\n",
        "    \n",
        "    if schema:\n",
        "        # Format the output as requested\n",
        "        classes_with_properties = {}\n",
        "        relationships = {}\n",
        "        \n",
        "        # Initialize classes dictionary\n",
        "        for cls in schema['classes']:\n",
        "            classes_with_properties[cls] = {}\n",
        "        \n",
        "        # Group datatype properties by their domain class\n",
        "        for prop_name, prop_info in schema['datatype_properties'].items():\n",
        "            domain = prop_info.get('domain')\n",
        "            range_type = prop_info.get('range', 'string')  # default to string if no range specified\n",
        "            \n",
        "            # Extract just the data type from the range URI if it's an XSD type\n",
        "            if range_type and 'XMLSchema#' in range_type:\n",
        "                range_type = range_type.split('#')[-1]\n",
        "            elif range_type and range_type.startswith('http://'):\n",
        "                range_type = range_type.split('/')[-1].split('#')[-1]\n",
        "            \n",
        "            if domain and domain in classes_with_properties:\n",
        "                classes_with_properties[domain][prop_name] = range_type\n",
        "        \n",
        "        # Format object properties as relationships\n",
        "        for relationship, rel_info in schema['object_properties'].items():\n",
        "            domain = rel_info.get('domain')\n",
        "            range_obj = rel_info.get('range')\n",
        "            relationships[relationship] = {\n",
        "                'domain': domain,\n",
        "                'range': range_obj\n",
        "            }\n",
        "\n",
        "        # Create the schema dictionary\n",
        "        schema_dict = {\n",
        "            'classes': classes_with_properties,\n",
        "            'relation': relationships\n",
        "        }\n",
        "        \n",
        "        # Convert to string and escape curly braces for LangChain compatibility\n",
        "        schema_str = str(schema_dict).replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "        \n",
        "        print(f\"Formatted schema: {schema_str}\")\n",
        "        \n",
        "        return schema_str\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check Question Relevance\n",
        "\n",
        "- CheckRelevance model: Defines the structure for relevance responses\n",
        "- check_relevance function: Evaluates if a question relates to the KG schema using LLM\n",
        "- Returns \"relevant\" or \"not_relevant\" to filter out unrelated questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CheckRelevance(BaseModel):\n",
        "    relevance: str = Field(\n",
        "        description=\"Indicates whether the question is related to the knowledge graph schema. 'relevant' or 'not_relevant'.\"\n",
        "    )\n",
        "\n",
        "# Check if the question is relevant to the knowledge graph schema\n",
        "def check_relevance(state: AgentState):\n",
        "    question = state[\"question\"]\n",
        "    schema = get_kg_schema()\n",
        "    print(f\"Checking relevance of the question: {question}\")\n",
        "    system = \"\"\"You are an assistant that determines whether a given question is related to the following knowledge graph schema.\n",
        "\n",
        "Schema:\n",
        "{schema}\n",
        "\n",
        "Respond with only \"relevant\" or \"not_relevant\".\n",
        "\"\"\".format(schema=schema)\n",
        "    human = f\"Question: {question}\"\n",
        "    check_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\"human\", human),\n",
        "        ]\n",
        "    )\n",
        "    llm = llm_from_api()\n",
        "    \n",
        "    relevance_checker = check_prompt | llm | StrOutputParser()\n",
        "    try:\n",
        "        relevance_response = relevance_checker.invoke({})\n",
        "        relevance_response = relevance_response.strip().lower()\n",
        "        \n",
        "        if \"not_relevant\" in relevance_response or \"not relevant\" in relevance_response:\n",
        "            state[\"relevance\"] = \"not_relevant\"\n",
        "        else:\n",
        "            state[\"relevance\"] = \"relevant\"\n",
        "            \n",
        "        print(f\"Relevance determined: {state['relevance']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking relevance: {str(e)}\")\n",
        "        state[\"relevance\"] = \"relevant\"  # Default to relevant on error\n",
        "    \n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SPARQL Query Generation\n",
        "- Defines ConvertToSPARQL model class with sparql_query field\n",
        "- Implements convert_nl_to_sparql function to transform natural language questions to SPARQL\n",
        "- Uses LLM to generate appropriate SPARQL based on knowledge graph schema\n",
        "- Handles query formatting and prefix inclusion\n",
        "- Updates agent state with generated SPARQL query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvertToSPARQL(BaseModel):\n",
        "    sparql_query: str = Field(\n",
        "        description=\"The SPARQL query corresponding to the user's natural language question.\"\n",
        "    )\n",
        "\n",
        "# Convert natural language question to SPARQL query\n",
        "def convert_nl_to_sparql(state: AgentState):\n",
        "    question = state[\"question\"]\n",
        "    schema = get_kg_schema()\n",
        "    print(f\"Converting question to SPARQL: {question}\")\n",
        "    system = \"\"\"You are an assistant that converts natural language questions into SPARQL queries based on the following knowledge graph schema:\n",
        "\n",
        "{schema}\n",
        "\n",
        "Undestand the relationships between the classes and properties.\n",
        "Also include FROM <https://a.in/sales/data> in the SPARQL query before where clause or after selecting the variables as per the syntax.\n",
        "\n",
        "Use these common prefixes:\n",
        "{prefixes}\n",
        "\n",
        "Provide only the SPARQL query without any explanations. Use appropriate variable names and include necessary JOINs via triple patterns.\n",
        "\n",
        "Return ONLY the SPARQL query, nothing else.\n",
        "\"\"\".format(schema=schema, prefixes=PREFIXES)\n",
        "    convert_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\"human\", \"Question: {question}\"),\n",
        "        ]\n",
        "    )\n",
        "    llm = llm_from_api()\n",
        "    \n",
        "    sparql_generator = convert_prompt | llm | StrOutputParser()\n",
        "    try:\n",
        "        sparql_query = sparql_generator.invoke({\"question\": question})\n",
        "        # Clean up the response to extract just the SPARQL\n",
        "        sparql_query = sparql_query.strip()\n",
        "        if sparql_query.startswith(\"```sparql\"):\n",
        "            sparql_query = sparql_query.replace(\"```sparql\", \"\").replace(\"```\", \"\").strip()\n",
        "        elif sparql_query.startswith(\"```\"):\n",
        "            sparql_query = sparql_query.replace(\"```\", \"\").strip()\n",
        "        \n",
        "        # Ensure prefixes are included\n",
        "        if not sparql_query.startswith(\"PREFIX\"):\n",
        "            sparql_query = PREFIXES + \"\\n\" + sparql_query\n",
        "        \n",
        "        state[\"sparql_query\"] = sparql_query\n",
        "        print(f\"Generated SPARQL query: {state['sparql_query']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating SPARQL: {str(e)}\")\n",
        "        state[\"sparql_query\"] = \"SELECT 'Error generating SPARQL query' as ?error WHERE {}\"\n",
        "        state[\"sparql_error\"] = True\n",
        "    \n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute SPARQL Query\n",
        "- Takes the SPARQL query from state and executes it against Stardog database\n",
        "- Handles query execution and result processing\n",
        "- Limits display to first 5 results for readability\n",
        "- Updates state with query results and any errors\n",
        "- Returns formatted results or error messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute SPARQL query against Stardog database and process results\n",
        "def execute_sparql(state: AgentState):\n",
        "    sparql_query = state[\"sparql_query\"].strip()\n",
        "    print(f\"Executing SPARQL query: {sparql_query}\")\n",
        "    try:\n",
        "        result = stardog_client.query(sparql_query, use_reasoning=True)\n",
        "        print(\"Executed Result\", result)\n",
        "        if result and 'results' in result:\n",
        "            bindings = result['results']['bindings']\n",
        "            if bindings:\n",
        "                state[\"query_results\"] = bindings\n",
        "                print(f\"Raw SPARQL Query Result: {state['query_results']}\")\n",
        "                # Format the result for readability\n",
        "                formatted_results = []\n",
        "                for binding in bindings[:5]:  # Limit to first 5 results for display\n",
        "                    result_dict = {}\n",
        "                    for var, value in binding.items():\n",
        "                        result_dict[var] = value.get('value', str(value))\n",
        "                    formatted_results.append(result_dict)\n",
        "                \n",
        "                if len(bindings) > 5:\n",
        "                    formatted_result = f\"Showing first 5 of {len(bindings)} results:\\n{formatted_results}\"\n",
        "                else:\n",
        "                    formatted_result = str(formatted_results)\n",
        "            else:\n",
        "                state[\"query_results\"] = []\n",
        "                formatted_result = \"No results found.\"\n",
        "            state[\"query_result\"] = formatted_result\n",
        "            state[\"sparql_error\"] = False\n",
        "            print(\"SPARQL SELECT query executed successfully.\")\n",
        "        else:\n",
        "            state[\"query_result\"] = \"Query executed but returned no data.\"\n",
        "            state[\"sparql_error\"] = False\n",
        "            print(\"SPARQL query executed successfully.\")\n",
        "    except Exception as e:\n",
        "        state[\"query_result\"] = f\"Error executing SPARQL query: {str(e)}\"\n",
        "        state[\"sparql_error\"] = True\n",
        "        print(f\"Error executing SPARQL query: {str(e)}\")\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Human Readable Answer\n",
        "- Takes SPARQL query results and converts them into natural language responses\n",
        "- Handles different cases: successful queries, no results, and errors\n",
        "- Uses prompt templates to structure responses appropriately\n",
        "- Escapes special characters in query and results to avoid formatting issues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate human-readable answer from SPARQL query results\n",
        "def generate_human_readable_answer(state: AgentState):\n",
        "    sparql = state[\"sparql_query\"].replace(\"{\", \"{{\").replace(\"}\", \"}}\")  # Escape curly braces in SPARQL query\n",
        "    result = str(state[\"query_result\"]).replace(\"{\", \"{{\").replace(\"}\", \"}}\")  # Escape curly braces in result\n",
        "    query_results = state.get(\"query_results\", [])\n",
        "    sparql_error = state.get(\"sparql_error\", False)\n",
        "    print(\"Generating a human-readable answer.\")\n",
        "    system = \"\"\"You are an assistant that converts SPARQL query results into clear, natural language responses for an e-commerce knowledge graph system.\n",
        "    \"\"\"\n",
        "    if sparql_error:\n",
        "        # Directly relay the error message\n",
        "        generate_prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\"system\", system),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    f\"\"\"SPARQL Query:\n",
        "{{sparql}}\n",
        "\n",
        "Result:\n",
        "{{result}}\n",
        "\n",
        "Formulate a clear and understandable error message informing about the issue.\"\"\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "    elif not query_results:\n",
        "        # Handle cases with no results\n",
        "        generate_prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\"system\", system),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    f\"\"\"SPARQL Query:\n",
        "{{sparql}}\n",
        "\n",
        "Result:\n",
        "{{result}}\n",
        "\n",
        "Formulate a clear and understandable answer to the original question and mention that no results were found for their query.\"\"\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "    else:\n",
        "        # Handle displaying results (orders, products, etc.)\n",
        "        generate_prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\"system\", system),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    f\"\"\"SPARQL Query:\n",
        "{{sparql}}\n",
        "\n",
        "Result:\n",
        "{{result}}\n",
        "\n",
        "Formulate a clear and understandable answer to the original question and present the information in a natural way. For purchases, mention product names and relevant details like prices or quantities.\"\"\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    llm = llm_from_api()\n",
        "    human_response = generate_prompt | llm | StrOutputParser()\n",
        "    answer = human_response.invoke({\"sparql\": sparql, \"result\": result})  # Explicitly pass variables\n",
        "    state[\"query_result\"] = answer\n",
        "    print(\"Generated human-readable answer.\")\n",
        "    return state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Query Regeneration\n",
        "- Reformulates the original question to enable more precise SPARQL queries\n",
        "- Uses LLM to rewrite questions while preserving key details\n",
        "- Tracks attempts and handles errors gracefully\n",
        "- Helps improve query accuracy by clarifying intent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RewrittenQuestion(BaseModel):\n",
        "    question: str = Field(description=\"The rewritten question.\")\n",
        "\n",
        "# Regenerate SPARQL query based on user question\n",
        "def regenerate_query(state: AgentState):\n",
        "    question = state[\"question\"]\n",
        "    print(\"Regenerating the SPARQL query by rewriting the question.\")\n",
        "    system = \"\"\"You are an assistant that reformulates an original question to enable more precise SPARQL queries for knowledge graphs. Ensure that all necessary details, such as entity relationships and properties, are preserved to retrieve complete and accurate data.\n",
        "    \n",
        "    Return only the reformulated question, nothing else.\n",
        "    \"\"\"\n",
        "    rewrite_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\n",
        "                \"human\",\n",
        "                f\"Original Question: {question}\\nReformulate the question to enable more precise SPARQL queries, ensuring all necessary details are preserved.\",\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    llm = llm_from_api()\n",
        "    \n",
        "    rewriter = rewrite_prompt | llm | StrOutputParser()\n",
        "    try:\n",
        "        rewritten_question = rewriter.invoke({})\n",
        "        state[\"question\"] = rewritten_question.strip()\n",
        "        state[\"attempts\"] += 1\n",
        "        print(f\"Rewritten question: {state['question']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error rewriting question: {str(e)}\")\n",
        "        state[\"attempts\"] += 1  # Still increment attempts even on error\n",
        "    \n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Funny Response Generation\n",
        "- Generates playful responses for unrelated or unsupported questions\n",
        "- Uses LLM to create engaging and humorous messages about knowledge graphs\n",
        "- Maintains user engagement even when direct answers aren't possible\n",
        "- Encourages exploration of knowledge graph capabilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate funny response for an unrelated question\n",
        "def generate_funny_response(state: AgentState):\n",
        "    print(\"Generating a funny response for an unrelated question.\")\n",
        "    system = \"\"\"You are a charming and funny assistant who responds in a playful manner about knowledge graphs.\n",
        "    \"\"\"\n",
        "    human_message = \"I can not help with that, but doesn't asking questions make you curious about fascinating knowledge connections? You can always explore some interesting relationships in our knowledge graph!\"\n",
        "    funny_prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system),\n",
        "            (\"human\", human_message),\n",
        "        ]\n",
        "    )\n",
        "    llm = llm_from_api()\n",
        "    funny_response = funny_prompt | llm | StrOutputParser()\n",
        "    message = funny_response.invoke({})\n",
        "    state[\"query_result\"] = message\n",
        "    print(\"Generated funny response.\")\n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result Format Router\n",
        "- Determines optimal format for query results based on size\n",
        "- Routes large result sets to table format for better readability\n",
        "- Handles SPARQL errors by triggering query regeneration\n",
        "- Processes small result sets into human-readable answers\n",
        "- Ensures efficient presentation of data with size thresholds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Determines whether to format results as a table or generate a human-readable answer based on result size.\n",
        "def format_result_router(state: AgentState):\n",
        "    \"\"\"Decides whether to format results as a table or generate a human-readable answer based on result size.\"\"\"\n",
        "    query_results = state.get(\"query_results\", [])\n",
        "    sparql_error = state.get(\"sparql_error\", False)\n",
        "    print(f\"Routing result format: {len(query_results)} results found.\")\n",
        "\n",
        "    # Define threshold for \"huge\" results\n",
        "    RESULT_THRESHOLD = 10\n",
        "\n",
        "    if sparql_error:\n",
        "        print(\"SPARQL error detected, routing to regenerate_query.\")\n",
        "        return {\"next_step\": \"regenerate_query\", \"query_result\": state[\"query_result\"]}\n",
        "    \n",
        "    if not query_results:\n",
        "        print(\"No results found, routing to generate_human_readable_answer.\")\n",
        "        return {\"next_step\": \"generate_human_readable_answer\", \"query_result\": state[\"query_result\"]}\n",
        "\n",
        "    if len(query_results) > RESULT_THRESHOLD:\n",
        "        print(\"Large result set detected, formatting as table.\")\n",
        "        # Format results as a table using tabulate\n",
        "        headers = list(query_results[0].keys())\n",
        "        \n",
        "        # Prepare data for tabulate\n",
        "        table_data = []\n",
        "        for result in query_results[:50]:  # Limit to 50 rows\n",
        "            row = [str(result.get(h, {}).get('value', \"\")) for h in headers]\n",
        "            table_data.append(row)\n",
        "        \n",
        "        # Use tabulate to format the table\n",
        "        table = tabulate(table_data, headers=headers, tablefmt=\"grid\")\n",
        "        \n",
        "        if len(query_results) > 50:\n",
        "            table += f\"\\n\\n*Showing first 50 of {len(query_results)} results.*\"\n",
        "        \n",
        "        state[\"query_result\"] = table\n",
        "        print(\"Table formatted successfully.\")\n",
        "        return {\"next_step\": END, \"query_result\": table}  # Return dictionary with END\n",
        "    else:\n",
        "        print(\"Small result set, routing to generate_human_readable_answer.\")\n",
        "        return {\"next_step\": \"generate_human_readable_answer\", \"query_result\": state[\"query_result\"]}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Result Routing Functions - Key Points\n",
        "- Handles routing logic for different workflow paths\n",
        "- Contains functions for checking attempts, relevance, and SPARQL execution\n",
        "- Implements error handling and retry logic\n",
        "- Manages workflow termination conditions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# End max iterations\n",
        "def end_max_iterations(state: AgentState):\n",
        "    state[\"query_result\"] = \"Please try again.\"\n",
        "    print(\"Maximum attempts reached. Ending the workflow.\")\n",
        "    return state\n",
        "\n",
        "# Relevance router\n",
        "def relevance_router(state: AgentState):\n",
        "    if state[\"relevance\"].lower() == \"relevant\":\n",
        "        return \"convert_to_sparql\"\n",
        "    else:\n",
        "        return \"generate_funny_response\"\n",
        "\n",
        "# Check attempts router\n",
        "def check_attempts_router(state: AgentState):\n",
        "    if state[\"attempts\"] < 3:\n",
        "        return \"convert_to_sparql\"\n",
        "    else:\n",
        "        return \"end_max_iterations\"\n",
        "\n",
        "# Execute SPARQL router\n",
        "def execute_sparql_router(state: AgentState):\n",
        "    if not state.get(\"sparql_error\", False):\n",
        "        return \"generate_human_readable_answer\"\n",
        "    else:\n",
        "        return \"regenerate_query\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Workflow Graph Definition\n",
        "- Defines the complete workflow structure using StateGraph\n",
        "- Adds nodes for each processing step (relevance check, SPARQL conversion, execution, etc.)\n",
        "- Establishes conditional edges between nodes based on routing logic\n",
        "- Implements branching paths for different scenarios (success, errors, max attempts)\n",
        "- Manages workflow termination conditions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the workflow graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"check_relevance\", check_relevance)\n",
        "workflow.add_node(\"convert_to_sparql\", convert_nl_to_sparql)\n",
        "workflow.add_node(\"execute_sparql\", execute_sparql)\n",
        "workflow.add_node(\"generate_human_readable_answer\", generate_human_readable_answer)\n",
        "workflow.add_node(\"regenerate_query\", regenerate_query)\n",
        "workflow.add_node(\"generate_funny_response\", generate_funny_response)\n",
        "workflow.add_node(\"end_max_iterations\", end_max_iterations)\n",
        "workflow.add_node(\"format_result_router\", format_result_router)\n",
        "\n",
        "# Define edges\n",
        "workflow.add_conditional_edges(\n",
        "    \"check_relevance\",\n",
        "    relevance_router,\n",
        "    {\n",
        "        \"convert_to_sparql\": \"convert_to_sparql\",\n",
        "        \"generate_funny_response\": \"generate_funny_response\",\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"convert_to_sparql\", \"execute_sparql\")\n",
        "\n",
        "workflow.add_edge(\"execute_sparql\", \"format_result_router\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"format_result_router\",\n",
        "    lambda state: state.get(\"next_step\", \"end\"),  # Use next_step from state\n",
        "    {\n",
        "        \"generate_human_readable_answer\": \"generate_human_readable_answer\",\n",
        "        \"regenerate_query\": \"regenerate_query\",\n",
        "        END: END,\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"regenerate_query\",\n",
        "    check_attempts_router,\n",
        "    {\n",
        "        \"convert_to_sparql\": \"convert_to_sparql\",\n",
        "        \"end_max_iterations\": \"end_max_iterations\",\n",
        "    },\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"generate_human_readable_answer\", END)\n",
        "workflow.add_edge(\"generate_funny_response\", END)\n",
        "workflow.add_edge(\"end_max_iterations\", END)\n",
        "\n",
        "workflow.set_entry_point(\"check_relevance\")\n",
        "\n",
        "# Compile the workflow\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"Stardog KG Agent workflow compiled successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Workflow Visualization - Displays the workflow graph\n",
        "- Uses IPython display to show the workflow visualization\n",
        "- Requires graphviz and pillow packages for rendering\n",
        "- Shows the complete flow of the Stardog KG Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
        "except:\n",
        "    print(\"Graph visualization not available - install graphviz and pillow if needed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Queries and Testing\n",
        " - Demonstrates usage of the Stardog KG Agent with sample questions\n",
        " - Tests product catalog queries and error handling\n",
        " - Shows how to handle both relevant and irrelevant queries\n",
        " - Requires a running Stardog instance with loaded data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Query orders and product details\n",
        "user_question_1 = \"List all the products families and thier products available\"\n",
        "try:\n",
        "    result_1 = app.invoke({\"question\": user_question_1, \"attempts\": 1})\n",
        "    print(\"Result:\", result_1[\"query_result\"])\n",
        "except Exception as e:\n",
        "    print(f\"Error running query: {e}\")\n",
        "    print(\"Note: This requires a running Stardog instance with the appropriate data loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Example 2: Test irrelevant question\n",
        "# user_question_2 = \"Tell me a joke about knowledge graphs.\"\n",
        "# try:\n",
        "#     result_2 = app.invoke({\"question\": user_question_2, \"attempts\": 1})\n",
        "#     print(\"Result:\", result_2[\"query_result\"])\n",
        "# except Exception as e:\n",
        "#     print(f\"Error running query: {e}\")\n",
        "#     print(\"Note: This requires a running Stardog instance and LLM configuration.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
