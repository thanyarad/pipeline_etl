from typing import Dict, Any
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from src.config.settings import PREFIXES, EXECUTE_FROM_STARDOG
from src.core.client import StardogClient
from src.core.models import AgentState
from src.core.memory import SessionMemory
from src.core.llm_manager import get_default_llm, get_llm_provider

class StardogAgent:
    def __init__(self, client: StardogClient, memory: SessionMemory = None, llm_provider: str = None):
        self.client = client
        self.llm = self._initialize_llm(llm_provider)
        self.memory = memory or SessionMemory(llm=self.llm)

    def _initialize_llm(self, llm_provider: str = None):
        """Initialize LLM using the specified provider or default."""
        if llm_provider:
            return get_llm_provider(llm_provider)
        else:
            return get_default_llm()

    def get_kg_schema(self):
        """Get a formatted schema summary with classes and relationships."""
        schema = self.client.get_schema()
        if schema:
            classes_with_properties = {}
            relationships = {}
            for cls in schema['classes']:
                classes_with_properties[cls] = {}
            for prop_name, prop_info in schema['datatype_properties'].items():
                domain = prop_info.get('domain')
                range_type = prop_info.get('range', 'string')
                if range_type and 'XMLSchema#' in range_type:
                    range_type = range_type.split('#')[-1]
                elif range_type and range_type.startswith('http://'):
                    range_type = range_type.split('/')[-1].split('#')[-1]
                if domain and domain in classes_with_properties:
                    classes_with_properties[domain][prop_name] = range_type
            for relationship, rel_info in schema['object_properties'].items():
                domain = rel_info.get('domain')
                range_obj = rel_info.get('range')
                relationships[relationship] = {'domain': domain, 'range': range_obj}
            schema_dict = {'classes': classes_with_properties, 'relation': relationships}
            schema_str = str(schema_dict).replace("{", "{{").replace("}", "}}")
            return schema_str
        return None

    def check_query_cache(self, state: AgentState) -> AgentState:
        """Check if the question can be answered from cache."""
        question = state["question"]
        cached_result = self.memory.check_query_cache(question)
        
        if cached_result:
            print(f"Using cached SPARQL query for: {question}")
            # Cache the SPARQL query but don't set the result
            # This allows re-execution to get fresh data
            state["sparql_query"] = cached_result['cached_sparql']
            state["cached_response"] = True
            state["cache_similarity"] = cached_result['similarity_score']
            # Don't set query_result - let it be generated by re-execution
        else:
            print(f"No cache hit for: {question}")
            state["cached_response"] = False
        
        return state

    def check_relevance(self, state: AgentState) -> AgentState:
        question = state["question"]
        
        # If we have a cached response, skip relevance check entirely
        if state.get("cached_response", False):
            print(f"Using cached response, skipping relevance check for: {question}")
            state["relevance"] = "relevant"  # Assume cached responses are relevant
            return state
        
        schema = self.get_kg_schema()
        conversation_context = self.memory.get_conversation_context()
        print(f"Checking relevance of the question: {question}")
        
        system = """You are an assistant that determines whether a given question is related to the following knowledge graph schema.

Schema:
{schema}

{context}
Consider the conversation context when determining relevance. If the question is a follow-up or clarification to a previous relevant question, mark it as relevant.

Respond with only "relevant" or "not_relevant".
""".format(schema=schema, context=conversation_context if conversation_context else "")
        
        human = f"Question: {question}"
        check_prompt = ChatPromptTemplate.from_messages([("system", system), ("human", human)])
        relevance_checker = check_prompt | self.llm | StrOutputParser()
        try:
            relevance_response = relevance_checker.invoke({})
            relevance_response = relevance_response.strip().lower()
            state["relevance"] = "not_relevant" if "not_relevant" in relevance_response else "relevant"
            print(f"Relevance determined: {state['relevance']}")
        except Exception as e:
            print(f"Error checking relevance: {str(e)}")
            state["relevance"] = "relevant"
        return state

    def convert_nl_to_sparql(self, state: AgentState) -> AgentState:
        question = state["question"]
        schema = self.get_kg_schema()
        conversation_context = self.memory.get_conversation_context()
        user_preferences = self.memory.get_user_preferences()
        print(f"Converting question to SPARQL: {question}")
        
        # Adapt query complexity based on user preferences
        complexity_note = ""
        if user_preferences.get("query_complexity") == "high":
            complexity_note = "The user prefers complex, detailed queries. Provide comprehensive SPARQL queries."
        elif user_preferences.get("query_complexity") == "low":
            complexity_note = "The user prefers simple, straightforward queries. Keep SPARQL queries concise."
        
        system = """You are an assistant that converts natural language questions into SPARQL queries based on the following knowledge graph schema:

{schema}

{context}

{complexity_note}

Understand the relationships between the classes and properties.
Include FROM {from_data} in the SPARQL query after the SELECT clause and before the WHERE clause.

Use these common prefixes:
{prefixes}

Consider the conversation context when generating queries. If this is a follow-up question, reference previous successful queries for consistency.

Provide only the SPARQL query without any explanations. Use appropriate variable names and include necessary JOINs via triple patterns.
""".format(schema=schema, context=conversation_context if conversation_context else "", 
           complexity_note=complexity_note, prefixes=PREFIXES, from_data=EXECUTE_FROM_STARDOG)
        
        convert_prompt = ChatPromptTemplate.from_messages([("system", system), ("human", "Question: {question}")])
        sparql_generator = convert_prompt | self.llm | StrOutputParser()
        try:
            sparql_query = sparql_generator.invoke({"question": question})
            sparql_query = sparql_query.strip()
            if sparql_query.startswith("```sparql"):
                sparql_query = sparql_query.replace("```sparql", "").replace("```", "").strip()
            elif sparql_query.startswith("```"):
                sparql_query = sparql_query.replace("```", "").strip()
            if not sparql_query.startswith("PREFIX"):
                sparql_query = PREFIXES + "\n" + sparql_query
            state["sparql_query"] = sparql_query
            print(f"Generated SPARQL query: {state['sparql_query']}")
        except Exception as e:
            print(f"Error generating SPARQL: {str(e)}")
            state["sparql_query"] = "SELECT 'Error generating SPARQL query' as ?error WHERE {}"
            state["sparql_error"] = True
        return state

    def execute_sparql(self, state: AgentState) -> AgentState:
        sparql_query = state["sparql_query"].strip()
        print(f"Executing SPARQL query: {sparql_query}")
        try:
            result = self.client.query(sparql_query, use_reasoning=True)
            print("Executed Result", result)
            if result and 'results' in result:
                bindings = result['results']['bindings']
                if bindings:
                    state["query_results"] = bindings
                    print(f"Raw SPARQL Query Result: {state['query_results']}")
                    formatted_results = []
                    for binding in bindings[:5]:
                        result_dict = {var: value.get('value', str(value)) for var, value in binding.items()}
                        formatted_results.append(result_dict)
                    formatted_result = str(formatted_results) if len(bindings) <= 5 else f"Showing first 5 of {len(bindings)} results:\n{formatted_results}"
                else:
                    state["query_results"] = []
                    formatted_result = "No results found."
                state["query_result"] = formatted_result
                state["sparql_error"] = False
                print("SPARQL SELECT query executed successfully.")
            else:
                state["query_result"] = "Query executed but returned no data."
                state["sparql_error"] = False
                print("SPARQL query executed successfully.")
        except Exception as e:
            state["query_result"] = f"Error executing SPARQL query: {str(e)}"
            state["sparql_error"] = True
            print(f"Error executing SPARQL query: {str(e)}")
        return state

    def generate_human_readable_answer(self, state: AgentState) -> AgentState:
        sparql = state["sparql_query"].replace("{", "{{").replace("}", "}}")
        result = str(state["query_result"]).replace("{", "{{").replace("}", "}}")
        query_results = state.get("query_results", [])
        sparql_error = state.get("sparql_error", False)
        conversation_context = self.memory.get_conversation_context()
        user_preferences = self.memory.get_user_preferences()
        print("Generating a human-readable answer.")
        
        # Adapt response detail level based on user preferences
        detail_note = ""
        if user_preferences.get("preferred_detail_level") == "high":
            detail_note = "Provide detailed, comprehensive responses with all relevant information."
        elif user_preferences.get("preferred_detail_level") == "low":
            detail_note = "Provide concise, to-the-point responses."
        else:
            detail_note = "Provide balanced responses with appropriate detail level."
        
        system = """You are an assistant that converts SPARQL query results into clear, natural language responses for an e-commerce knowledge graph system.

{context}

{detail_note}

Consider the conversation context when formulating responses. If this is a follow-up question, reference previous information appropriately.
""".format(context=conversation_context if conversation_context else "", detail_note=detail_note)
        
        if sparql_error:
            generate_prompt = ChatPromptTemplate.from_messages([
                ("system", system),
                ("human", f"""SPARQL Query:\n{{sparql}}\n\nResult:\n\n{{result}}\n\nFormulate a clear and understandable error message informing about the issue."""),
            ])
        elif not query_results:
            generate_prompt = ChatPromptTemplate.from_messages([
                ("system", system),
                ("human", f"""SPARQL Query:\n{{sparql}}\n\nResult:\n\n{{result}}\n\nFormulate a clear and understandable answer to the original question and mention that no results were found for their query."""),
            ])
        else:
            generate_prompt = ChatPromptTemplate.from_messages([
                ("system", system),
                ("human", f"""SPARQL Query:\n{{sparql}}\n\nResult:\n\n{{result}}\n\nFormulate a clear and understandable answer to the original question and present the information in a natural way. For purchases, mention product names and relevant details like prices or quantities."""),
            ])
        human_response = generate_prompt | self.llm | StrOutputParser()
        answer = human_response.invoke({"sparql": sparql, "result": result})
        state["query_result"] = answer
        print("Generated human-readable answer.")
        return state

    def regenerate_query(self, state: AgentState) -> AgentState:
        question = state["question"]
        print("Regenerating the SPARQL query by rewriting the question.")
        system = """You are an assistant that reformulates an original question to enable more precise SPARQL queries for knowledge graphs. Ensure that all necessary details, such as entity relationships and properties, are preserved to retrieve complete and accurate data.
        
        Return only the reformulated question, nothing else."""
        rewrite_prompt = ChatPromptTemplate.from_messages([
            ("system", system),
            ("human", f"Original Question: {question}\nReformulate the question to enable more precise SPARQL queries, ensuring all necessary details are preserved."),
        ])
        rewriter = rewrite_prompt | self.llm | StrOutputParser()
        try:
            rewritten_question = rewriter.invoke({})
            state["question"] = rewritten_question.strip()
            state["attempts"] += 1
            print(f"Rewritten question: {state['question']}")
        except Exception as e:
            print(f"Error rewriting question: {str(e)}")
            state["attempts"] += 1
        return state

    def generate_funny_response(self, state: AgentState) -> AgentState:
        print("Generating a funny response for an unrelated question.")
        system = """You are a charming and funny assistant who responds in a playful manner about knowledge graphs."""
        human_message = "I can not help with that, but doesn't asking questions make you curious about fascinating knowledge connections? You can always explore some interesting relationships in our knowledge graph!"
        funny_prompt = ChatPromptTemplate.from_messages([("system", system), ("human", human_message)])
        funny_response = funny_prompt | self.llm | StrOutputParser()
        message = funny_response.invoke({})
        state["query_result"] = message
        print("Generated funny response.")
        return state
    
    def update_memory(self, state: AgentState) -> AgentState:
        """Update the agent's memory with the current interaction."""
        self.memory.add_memory_entry(state)
        print(f"Memory updated for session: {self.memory.session_id}")
        return state
    
    def get_memory_info(self) -> Dict[str, Any]:
        """Get information about the current memory state."""
        return {
            "session_id": self.memory.session_id,
            "conversation_count": len(self.memory.conversation_history),
            "user_preferences": self.memory.get_user_preferences(),
            "context_summary": self.memory.context_summary
        }
    
    def clear_memory(self) -> None:
        """Clear the agent's memory."""
        self.memory.clear_memory()
        print("Memory cleared.")