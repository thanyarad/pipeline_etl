{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81ee6470-324c-4931-871b-83b40041b926",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Silver Layer Transformation Script for cpg_consumer\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import IntegerType, BooleanType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "916750b1-7ff3-4193-ab0b-23a9a8b757c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_consumer\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_consumer_order\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_order_items\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_consumer_invoice\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_distributor\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_distributor_purchases\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_distributor_purchase_items\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_distributor_invoice\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_product\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS cpg_industry.silver.cpg_inventory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad0e9fcc-1fea-4688-8d2f-ba1a3cde22e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_consumer\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"consumer_id\"])\n",
    "      .dropna(subset=[\"consumer_id\", \"email\", \"registration_date\"])\n",
    "      .withColumn(\"age\", col(\"age\").cast(IntegerType()))\n",
    "      .withColumn(\"is_active\", col(\"is_active\").cast(BooleanType()))\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_consumer\")\n",
    "\n",
    "# Silver Layer Transformation Script for cpg_consumer_order\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_consumer_order\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"order_id\"])\n",
    "      .dropna(subset=[\"order_id\", \"consumer_id\", \"order_date\"])\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_consumer_order\")\n",
    "\n",
    "# Silver Layer Transformation Script for cpg_order_items\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_order_items\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"order_item_id\"])\n",
    "      .dropna(subset=[\"order_item_id\", \"order_id\", \"product_id\"])\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_order_items\")\n",
    "\n",
    "# Silver Layer Transformation Script for cpg_consumer_invoice\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_consumer_invoice\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"invoice_id\"])\n",
    "      .dropna(subset=[\"invoice_id\", \"order_id\", \"consumer_id\"])\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_consumer_invoice\")\n",
    "\n",
    "# Silver Layer Transformation Script for cpg_inventory\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_inventory\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"inventory_id\"])\n",
    "      .dropna(subset=[\"inventory_id\", \"product_id\"])\n",
    "      .withColumn(\"location_type\", col(\"location_type\").cast(StringType()))\n",
    "      .withColumn(\"location_is_active\", col(\"location_is_active\").cast(BooleanType()))\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_inventory\")\n",
    "\n",
    "# Silver Layer Transformation Script for cpg_product\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_product\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"product_id\"])\n",
    "      .dropna(subset=[\"product_id\", \"product_name\"])\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_product\")\n",
    "\n",
    "# Silver Layer Transformation Script for cpg_distributor_purchases\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_distributor_purchases\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"purchase_id\"])\n",
    "      .dropna(subset=[\"purchase_id\", \"order_date\"])\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_distributor_purchases\")\n",
    "\n",
    "# Silver Layer Transformation Script for cpg_distributor_purchase_items\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_distributor_purchase_items\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"purchase_item_id\"])\n",
    "      .dropna(subset=[\"purchase_item_id\", \"purchase_id\", \"product_id\"])\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_distributor_purchase_items\")\n",
    "\n",
    "# Silver Layer Transformation Script for cpg_distributor_invoice\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_distributor_invoice\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"invoice_id\"])\n",
    "      .dropna(subset=[\"invoice_id\", \"purchase_id\"])\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_distributor_invoice\")\n",
    "\n",
    "# Silver Layer Transformation Script for cpg_distributor\n",
    "df = spark.read.table(\"cpg_industry.bronze.cpg_distributor\")\n",
    "df_clean = (\n",
    "    df.dropDuplicates([\"distributor_id\"])\n",
    "      .dropna(subset=[\"distributor_id\", \"distributor_name\"])\n",
    ")\n",
    "df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"cpg_industry.silver.cpg_distributor\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
